{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%run Grid_world.ipynb\n",
    "import import_ipynb\n",
    "from Iterative_Policy_Evaluation import print_values, print_policy, fixed_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_ENOUGH = 1e-5\n",
    "GAMMA = 0.9\n",
    "ALL_POSSIBLE_ACTIONS = ('U', 'D', 'L', 'R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(grid, policy):\n",
    "    \"\"\"Returns the state, action, returns tuple for each state encountered in the episode\"\"\"\n",
    "    \n",
    "    #Chose starting position randomly\n",
    "    possible_start_states = list(grid.actions.keys())\n",
    "    random_start_idx = np.random.choice(len(possible_start_states))\n",
    "    grid.set_state(possible_start_states[random_start_idx])\n",
    "    \n",
    "    #Chose first action randomly (Exploring start)\n",
    "    action = np.random.choice(ALL_POSSIBLE_ACTIONS)\n",
    "    \n",
    "    #\n",
    "    s = grid.current_state()\n",
    "    states_actions_rewards = [(s,action,0.0)] #Assign zero reward to starting state and action\n",
    "    #Play game using the policy and collect states and rewards\n",
    "    seen_states = set()\n",
    "    seen_states.add(s)\n",
    "    num_steps = 0\n",
    "    while not grid.game_over():\n",
    "        num_steps += 1\n",
    "        old_state = s\n",
    "        reward = grid.move(action)\n",
    "        s = grid.current_state()\n",
    "        \n",
    "        if s in seen_states:  #Terminate episode if the states run into a loop\n",
    "            states_actions_rewards.append((s,None, -10.0/num_steps))\n",
    "            break\n",
    "        elif grid.game_over():\n",
    "            states_actions_rewards.append((s,None, reward))\n",
    "            break\n",
    "        else:\n",
    "            action = policy[s]\n",
    "            states_actions_rewards.append((s,action,reward))\n",
    "        seen_states.add(s)\n",
    "            \n",
    "    states_actions_returns = []    \n",
    "    G = 0\n",
    "    first = True\n",
    "    for s,a,r in reversed(states_actions_rewards):\n",
    "    # the value of the terminal state is 0 by definition\n",
    "    # we should ignore the first state we encounter\n",
    "    # and ignore the last G, which is meaningless since it doesn't correspond to any move\n",
    "        if first:\n",
    "            G = 0 #Terminal state has no future reward\n",
    "            first = False\n",
    "        else:\n",
    "            states_actions_returns.append((s,a,G))\n",
    "        G = r + GAMMA*G\n",
    "    \n",
    "    states_actions_returns.reverse()\n",
    "    return states_actions_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_dict(d):\n",
    "    # returns the argmax (key) and max (value) from a dictionary\n",
    "    # put this into a function since we are using it so often\n",
    "    max_key = None\n",
    "    max_val = float('-inf')\n",
    "    for k, v in d.items():\n",
    "        if v > max_val:\n",
    "            max_val = v\n",
    "            max_key = k\n",
    "    return max_key, max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:\n",
      "---------------------------\n",
      " 0.00| 0.00| 0.00| 1.00|\n",
      "---------------------------\n",
      " 0.00| 0.00| 0.00|-1.00|\n",
      "---------------------------\n",
      " 0.00| 0.00| 0.00| 0.00|\n",
      "\n",
      "Initial random policy:\n",
      "---------------------------\n",
      "  U  |  D  |  U  |     |\n",
      "---------------------------\n",
      "  L  |     |  D  |     |\n",
      "---------------------------\n",
      "  L  |  R  |  D  |  U  |\n",
      "\n",
      "Final policy:\n",
      "---------------------------\n",
      "  R  |  R  |  R  |     |\n",
      "---------------------------\n",
      "  D  |     |  U  |     |\n",
      "---------------------------\n",
      "  R  |  R  |  U  |  U  |\n",
      "\n",
      "Final values:\n",
      "---------------------------\n",
      "-0.64|-0.43| 1.00| 0.00|\n",
      "---------------------------\n",
      "-0.87| 0.00| 0.14| 0.00|\n",
      "---------------------------\n",
      "-0.85|-0.49|-0.09|-1.00|\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ ==  \"__main__\":\n",
    "    grid = standard_grid()\n",
    "    \n",
    "    # print rewards\n",
    "    print(\"rewards:\")\n",
    "    print_values(grid.rewards, grid)\n",
    "    \n",
    "    #Randomly generate a policy\n",
    "    policy = {}\n",
    "    for s in grid.actions.keys():\n",
    "        policy[s] = np.random.choice(ALL_POSSIBLE_ACTIONS)\n",
    "    \n",
    "    print(\"\\nInitial random policy:\")\n",
    "    print_policy(policy, grid)\n",
    "    \n",
    "    # initialize Q(s,a) and returns for all possible states and actions\n",
    "    Q = {}\n",
    "    returns = {} # dictionary of state -> list of returns we've received\n",
    "    states = grid.all_states()\n",
    "    for s in states:\n",
    "        if s in grid.actions: # not a terminal state\n",
    "            Q[s] = {}\n",
    "            for a in ALL_POSSIBLE_ACTIONS:\n",
    "                Q[s][a] = 0 # needs to be initialized to something so we can argmax it\n",
    "                returns[(s,a)] = []\n",
    "        else:\n",
    "           # terminal state or state we can't otherwise get to\n",
    "           pass\n",
    "    \n",
    "    #play games, avg the returns and update policy\n",
    "    deltas = []\n",
    "    min_itr = -100\n",
    "    for i in range(20000):\n",
    "        biggest_change = 0\n",
    "        states_actions_returns = play_game(grid,policy)\n",
    "        seen_states_actions = set()\n",
    "        for s, a, G in states_actions_returns:\n",
    "          # check if we have already seen s\n",
    "          # called \"first-visit\" MC policy evaluation\n",
    "            if (s,a) not in seen_states_actions:\n",
    "                old_q = Q[s][a]\n",
    "                returns[(s,a)].append(G)\n",
    "                Q[s][a] = np.mean(returns[(s,a)])\n",
    "                biggest_change = max(biggest_change, np.abs(old_q - Q[s][a]))\n",
    "                seen_states_actions.add((s,a))\n",
    "        \n",
    "        if (biggest_change < SMALL_ENOUGH) & (min_itr < 0):\n",
    "            min_itr = i\n",
    "            \n",
    "        deltas.append(biggest_change)\n",
    "        \n",
    "        #Policy Update, happens for each episode\n",
    "        for s in policy.keys():\n",
    "            policy[s] = max_dict(Q[s])[0]\n",
    "            \n",
    "            \n",
    "    # final Policy\n",
    "    print(\"\\nFinal policy:\")\n",
    "    print_policy(policy, grid)\n",
    "    \n",
    "    # find V\n",
    "    V = {}\n",
    "    for s, Qs in Q.items():\n",
    "        V[s] = max_dict(Q[s])[1]\n",
    "\n",
    "    #print(\"Min Iterations needed\", min_itr)    \n",
    "    print(\"\\nFinal values:\")\n",
    "    print_values(V, grid)\n",
    "    \n",
    "    plt.plot(deltas)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
