{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Iterative Policy Evaluation.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%run Grid_world.ipynb\n",
    "import import_ipynb\n",
    "from Iterative_Policy_Evaluation import print_values, print_policy, fixed_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_ENOUGH = 1e-5\n",
    "GAMMA = 0.9\n",
    "ALL_POSSIBLE_ACTIONS = ('U', 'D', 'L', 'R')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_action(a, eps=0.2):\n",
    "    \"\"\"Chose the given action with probability (1- eps) and choose randomly otherwise.\"\"\"\n",
    "    p = np.random.random()\n",
    "    if p < (1-eps):\n",
    "        return a\n",
    "    else:\n",
    "        return np.random.choice(ALL_POSSIBLE_ACTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(grid, policy, start_pos=(2,0)):\n",
    "    \"\"\"Returns the state, action, returns tuple for each state encountered in the episode\"\"\"\n",
    "    \n",
    "    \n",
    "    #Start form fixed position everytime\n",
    "    grid.set_state(start_pos)\n",
    "    s = grid.current_state()\n",
    "    \n",
    "    #Chose action using random action function (epsilon-greedy)\n",
    "    action = random_action(policy[s])\n",
    "       \n",
    "    states_actions_rewards = [(s,action,0.0)] #Assign zero reward to starting state and action\n",
    "    #Play game using the policy and collect states and rewards\n",
    "    seen_states = set()\n",
    "    seen_states.add(s)\n",
    "    num_steps = 0\n",
    "    while not grid.game_over():\n",
    "        num_steps += 1\n",
    "        old_state = s\n",
    "        reward = grid.move(action)\n",
    "        s = grid.current_state()\n",
    "        \n",
    "        if s in seen_states:  #Terminate episode if the states run into a loop\n",
    "            states_actions_rewards.append((s,None, -10.0/num_steps))\n",
    "            break\n",
    "        elif grid.game_over():\n",
    "            states_actions_rewards.append((s,None, reward))\n",
    "            break\n",
    "        else:\n",
    "            action = random_action(policy[s])\n",
    "            states_actions_rewards.append((s,action,reward))\n",
    "        seen_states.add(s)\n",
    "            \n",
    "    states_actions_returns = []    \n",
    "    G = 0\n",
    "    first = True\n",
    "    for s,a,r in reversed(states_actions_rewards):\n",
    "    # the value of the terminal state is 0 by definition\n",
    "    # we should ignore the first state we encounter\n",
    "    # and ignore the last G, which is meaningless since it doesn't correspond to any move\n",
    "        if first:\n",
    "            G = 0 #Terminal state has no future reward\n",
    "            first = False\n",
    "        else:\n",
    "            states_actions_returns.append((s,a,G))\n",
    "        G = r + GAMMA*G\n",
    "    \n",
    "    states_actions_returns.reverse()\n",
    "    return states_actions_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_dict(d):\n",
    "    # returns the argmax (key) and max (value) from a dictionary\n",
    "    # put this into a function since we are using it so often\n",
    "    max_key = None\n",
    "    max_val = float('-inf')\n",
    "    for k, v in d.items():\n",
    "        if v > max_val:\n",
    "            max_val = v\n",
    "            max_key = k\n",
    "    return max_key, max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10| 1.00|\n",
      "---------------------------\n",
      "-0.10| 0.00|-0.10|-1.00|\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10|-0.10|\n",
      "\n",
      "Initial random policy:\n",
      "---------------------------\n",
      "  U  |  R  |  D  |     |\n",
      "---------------------------\n",
      "  U  |     |  U  |     |\n",
      "---------------------------\n",
      "  D  |  U  |  L  |  L  |\n",
      "\n",
      "Final policy:\n",
      "---------------------------\n",
      "  R  |  R  |  R  |     |\n",
      "---------------------------\n",
      "  U  |     |  U  |     |\n",
      "---------------------------\n",
      "  U  |  R  |  U  |  U  |\n",
      "\n",
      "Final values:\n",
      "---------------------------\n",
      "-0.11| 0.41| 1.00| 0.00|\n",
      "---------------------------\n",
      "-0.64| 0.00|-0.44| 0.00|\n",
      "---------------------------\n",
      "-1.26|-0.62|-0.24|-1.00|\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ ==  \"__main__\":\n",
    "    grid = negative_grid()\n",
    "    \n",
    "    # print rewards\n",
    "    print(\"rewards:\")\n",
    "    print_values(grid.rewards, grid)\n",
    "    \n",
    "    #Randomly generate a policy\n",
    "    policy = {}\n",
    "    for s in grid.actions.keys():\n",
    "        policy[s] = np.random.choice(ALL_POSSIBLE_ACTIONS)\n",
    "    \n",
    "    print(\"\\nInitial random policy:\")\n",
    "    print_policy(policy, grid)\n",
    "    \n",
    "    # initialize Q(s,a) and returns for all possible states and actions\n",
    "    Q = {}\n",
    "    returns = {} # dictionary of state -> list of returns we've received\n",
    "    states = grid.all_states()\n",
    "    for s in states:\n",
    "        if s in grid.actions: # not a terminal state\n",
    "            Q[s] = {}\n",
    "            for a in ALL_POSSIBLE_ACTIONS:\n",
    "                Q[s][a] = 0 # needs to be initialized to something so we can argmax it\n",
    "                returns[(s,a)] = []\n",
    "        else:\n",
    "           # terminal state or state we can't otherwise get to\n",
    "           pass\n",
    "    \n",
    "    #play games, avg the returns and update policy\n",
    "    deltas = []\n",
    "    min_itr = -100\n",
    "    for i in range(20000):\n",
    "        biggest_change = 0\n",
    "        states_actions_returns = play_game(grid,policy,start_pos=(2,0))\n",
    "        seen_states_actions = set()\n",
    "        for s, a, G in states_actions_returns:\n",
    "          # check if we have already seen s\n",
    "          # called \"first-visit\" MC policy evaluation\n",
    "            if (s,a) not in seen_states_actions:\n",
    "                old_q = Q[s][a]\n",
    "                returns[(s,a)].append(G)\n",
    "                Q[s][a] = np.mean(returns[(s,a)])\n",
    "                biggest_change = max(biggest_change, np.abs(old_q - Q[s][a]))\n",
    "                seen_states_actions.add((s,a))\n",
    "        \n",
    "        if (biggest_change < SMALL_ENOUGH) & (min_itr < 0):\n",
    "            min_itr = i\n",
    "            \n",
    "        deltas.append(biggest_change)\n",
    "        \n",
    "        #Policy Update, happens for each episode\n",
    "        for s in policy.keys():\n",
    "            policy[s] = max_dict(Q[s])[0]\n",
    "            \n",
    "            \n",
    "    # final Policy\n",
    "    print(\"\\nFinal policy:\")\n",
    "    print_policy(policy, grid)\n",
    "    \n",
    "    # find V\n",
    "    V = {}\n",
    "    for s, Qs in Q.items():\n",
    "        V[s] = max_dict(Q[s])[1]\n",
    "\n",
    "    #print(\"Min Iterations needed\", min_itr)    \n",
    "    print(\"\\nFinal values:\")\n",
    "    print_values(V, grid)\n",
    "    \n",
    "    plt.plot(deltas)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
